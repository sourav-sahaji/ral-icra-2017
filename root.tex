%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{url}
\usepackage{graphicx}
\usepackage{color}
\graphicspath{{./images/}}

\title{\LARGE \bf
Improving Condition- and Environment-Invariant Place Recognition with Semantic Place Categorization
}

\author{Albert Author$^{1}$ and Bernard D. Researcher$^{2}$% <-this % stops a space
\thanks{*This work was not supported by any organization}% <-this % stops a space
\thanks{$^{1}$Albert Author is with Faculty of Electrical Engineering, Mathematics and Computer Science,
        University of Twente, 7500 AE Enschede, The Netherlands
        {\tt\small albert.author@papercept.net}}%
\thanks{$^{2}$Bernard D. Researcheris with the Department of Electrical Engineering, Wright State University,
        Dayton, OH 45435, USA
        {\tt\small b.d.researcher@ieee.org}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
The problem of place recognition actually comprises two distinct subproblems; "ordinary" place recognition which is recognizing a specific location in the world, and place "categorization", which involves recognizing the type of place. Both components of place recognition are competencies for robotic navigation systems and hence have each in isolation received significant attention in the robotics and computer vision community. In this paper, we leverage the powerful complementary nature of the place recognition and place categorization processes to create a new state-of-the-art ordinary place recognition system that uses place context to inform place recognition. We show that semantic place categorization creates a more informative natural segmenting of physical space than the blindly applied fixed segmentation used in algorithms such as SeqSLAM, which enables significantly better place recognition performance. In particular, where existing condition-invariant algorithms enable robustness to globally consistent change (such as day to night cycles), this new semantically informed approach adds robustness to significant changes within the environment, such as transitioning from indoor to outdoor environments. We perform a number of experiments using benchmark and new datasets and show that semantically-informed place recognition outperforms the previous state of the art systems. Like it does for object recognition [ref Niko IROS2015], we believe that  semantics can play a key role in boosting conventional place recognition and navigation performance for robotic systems.
\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

\section{Related Work}

\section{Proposed Method}
The proposed approach has two main components: place categorization and place recognition as depicted in Fig. \ref{fig:flowchart}, with semantic information flowing from the former to the latter to generate the final outcome. The semantic labels divide the physical space into different regions based on its appearance, that is, scene attributes. These segmented regions are then used for improving the place recognition performance. We use CNN model VGG16-places365 \cite{cnnPlaces365Github} pre-trained on Places365 database \cite{zhou2014learning} for labeling reference and query database images as indoor or outdoor along with scene attributes \cite{Patterson2012SunAttributes} prediction. We use SeqSLAM \cite{Milford2012} for showing improved place recognition using semantic information by appropriately enhancing the image matching scores.

\begin{figure}
 \includegraphics[clip, trim=1cm 5cm 0cm 2cm,scale=0.3]{flowchart}
 \caption{A block diagram showing flow of semantic information from the place categorization module to the place recognition module for generating the final outcome.}
 \label{fig:flowchart}
\end{figure}


\subsection{Place Categorization}

\subsubsection{Image Classification}

% The pre-trained CNN model classifies an image with probabilities associated with each of the 365 place categories. 205 of these place categories also have binary labels classifying an image as indoor or outdoor. We added the indoor/outdoor labels for rest of the 160 place categories. We use top-5 most probable predictions from the pre-trained model to calculate a weighted score for labeling an image as indoor or outdoor. Figure \ref{fig:labelledImages} shows images with indoor/outdoor label, top predicted place label and its associated probability.

The pre-trained CNN model classifies an image with probabilities associated with each of the 365 place categories. It also predicts the most probable scene attributes (out of 102 attributes trained on SUN database \cite{Patterson2012SunAttributes}) using one of its fully-connected layers. We use the top-5 most probable attribute predictions for post-processing the image labels to semantically segment datasets. The classification is performed on the entire reference and query database. The reference database labels are used for temporally dividing the image sequence into different chunks based on its scene attributes. The query database labels are used later during place recognition for identifying the correct semantic segment of reference database and effectively matching the image sequence.

\newcommand{\scaleVal}{0.28}
\begin{figure*}[!htbp]
 \begin{tabular*}{\textwidth}{lcr}
  \includegraphics[scale=\scaleVal]{1-corridor} &
  \includegraphics[scale=\scaleVal]{2-staircase} &
%  \includegraphics[scale=\scaleVal]{3-campus} &
  \includegraphics[scale=\scaleVal]{4-fieldRoad} \\
  & (a) & \\
%  \includegraphics[scale=\scaleVal]{5-lawn} &
  \includegraphics[scale=\scaleVal]{6-subwayStation} &
  \includegraphics[scale=\scaleVal]{7-railroadTrack} &
  \includegraphics[scale=\scaleVal]{8-trainStation} \\
  & (b) &
 \end{tabular*}
 \caption{Images from reference database with indoor/outdoor labels, top predicted label from 365 place categories and its associated probability. (a) Campus Dataset and (b) CTA Rail Dataset}
 \label{fig:labelledImages}
\end{figure*}

\subsubsection{Dataset Segmentation}
The image labels for reference database obtained from the classifier do not usually exhibit local temporal persistence of their labels. In order to achieve an adequate dataset segmentation, we find temporal connected components in the database. Each image in the database is represented by a node $N_i$ defined as a set containing the top-5 predicted labels and the most probable prediction label $L_i$. A consecutive pair of nodes is considered to be connected if an edge $E_{i,i+1}$ exists between them as per Eq. \ref{eq:connectedComponent}.
\begin{equation}
 E_{i,i+1} = 
 \begin{cases}
  1, & \text{if } \left\vert{N_i \cap N_{i+1}}\right\vert \geq 3\\
  0, & \text{otherwise}
 \end{cases}
 \label{eq:connectedComponent}
\end{equation}

The edges between the nodes can be determined by a single pass over the entire image sequence. A new connected component is obtained whenever an edge between consecutive nodes ceases to exist. The most probable prediction label $L_i$ of each node in a connected component is used to find the most frequently occurring label $L'_i$ within that component. This label $L'_i$ is used for representing the connected component as well as each of its nodes. These newly obtained labels are further filtered to get rid of transient errors. We use a sliding window of size $s$ that passes through the entire image sequence and replaces the label $L'_i$ by the mode of labels in the sliding window as given in Eq. \ref{eq:labelsMode}, where $M(X)$ for a set $X$ gives the statistical mode of the set.
\begin{equation}
 \hat{L}_i = M(\bigcup\limits_{i-s/2}^{i+s/2} L'_i)
 \label{eq:labelsMode}
\end{equation}

The filtered image labels $\hat{L}_i$ are finally used to segment the database into different chunks. These chunks represent the variation in appearance of the environment while traversing the route. For example, a train running underground as opposed to over the ground will have different appearance of its environment. Similarly, a person walking indoor or outdoor of a campus will witness different surrounding environment as shown in Fig. \ref{fig:labelledImages}. Fig. \ref{fig:datasetLabels} shows the images and their semantic labels at the segmentation transition points for one of the datasets used in this paper.

\begin{figure}[!htbp]
 \includegraphics[clip, trim=2cm 4cm 2cm 4cm,scale=0.35]{cta-dataset-segmentation-1}
 \caption{The time-line of CTA-Rail dataset with semantically labeled images at the transition points of segmented reference database. (Time-line created using \cite{timelineRWT}})
 \label{fig:datasetLabels}
\end{figure}

\subsection{Place Recognition}
In general, a place recognition system comprises of a pre-processing stage, then a method to calculate affinity scores between database places and the query, and finally a decision module for generating the best matching pairs. This is also depicted in Fig. \ref{fig:flowchart}.
\subsubsection{Sequence-based recognition}
In addition to the above mentioned place recognition pipeline, a sequence-based recognition method exploits the temporal information inherent in this problem. Therefore, searching for a matching sequence of places is a better approach than deciding a match based only on single matching template from reference imagery. SeqSLAM \cite{Milford2012} is a sequence-based place recognition method developed on similar principle. Moreover, it is known to work remarkably well in challenging environmental conditions and is able to recognize places despite seasonal, weather or time of day variations. The recent advanced methods \cite{milford2015sequence}, \cite{wang2015improved}, \cite{milford2015place} etc. inspired from SeqSLAM further improve the state-of-the-art for place recognition. In this paper, we use the vanilla approach to show the performance improvement of a place recognition system, under the influence of variations in the surrounding environment, with the help of semantic information associated with those places. The detailed methodology of SeqSLAM can be referred to in \cite{Milford2012}.

SeqSLAM performs place recognition using Sum of Absolute Difference (SAD) scores represented as $D$ between preprocessed reference and query images. The preprocessing step involves down-sampling of image to size $S_x$ and $S_y$ and patch normalizing it with a fixed square window of side length $P$.
\begin{equation}
 D_i = \frac{1}{S_xS_y} \sum\limits_{x=0}^{S_x}\sum\limits_{y=0}^{S_y}|p_{x,y}^i-p_{x,y}|
 \label{eq:SADscore}
\end{equation}
where $p_{x,y}^i$ and $p_{x,y}$ are the pixel intensities of patch normalized query and reference images.

The difference vector so obtained for each query image is normalized within a sliding window of size $R$. The normalized difference $\hat{D_i}$ is calculated using the local mean difference $\bar{D_i}$ and local standard deviation $\sigma_i$.
\begin{equation}
 \hat{D_i} = \frac{D_i-\bar{D_i}}{\sigma_i}
 \label{eq:normScore}
\end{equation}

The normalized SAD matrix is then searched for local image sequence trajectories of length $d_s$, within a limited range of velocities, originating from each of the reference image. The sequence trajectory with best score is then selected using a trajectory uniqueness threshold $\mu$.

The normalization of place matching scores from Eq. \ref{eq:SADscore} within the window $R$, as calculated in Eq. \ref{eq:normScore} reflects the emphasis on matching a local physical region of the environment. The parameter $R$ represents the span of environment, where the matching scores are locally enhanced. Our aim is to pre-define the physical regions of the environment for effectively matching the places that share similar semantic labels. The subsequent section shows how this can be achieved using the place recognition method chosen above.

\subsubsection{Segmented Region Normalization}
The score normalization step in SeqSLAM uses an arbitrary window size for locally normalizing the matching scores as given in Eq. \ref{eq:normScore}. We use the segmented regions of the dataset to set the normalization window of each query image. The label associated with the query image is used to identify the matching regions of dataset where the normalization is performed with window size equivalent to the size of the matching region. The unmatched regions use the vanilla method of contrast enhancement.

\section{Experimental Setup}
The experiments are performed using two datasets described in subsequent section. The image classification is performed using Dell M4800 Intel Core i7, 3.1 GHz processor with NVIDIA Quadro K2100M graphics card. The place recognition is performed using Dell E7450 Intel Core i7, 2.6 GHz processor. The classification is done as a preprocessing step for reference as well as query database off-line.

\subsection{Dataset}
The two datasets used in the experiments have instances of different environmental appearances as the route is traversed.

\subsubsection{CTA-Rail}
The CTA-Rail (Chicago Transit Authority) dataset (Fig. \ref{fig:ctaTraj}) comprises of two videos traversing a 23 km railway route (Blue Line to O'Hare) recorded once in 2014 \cite{ctaRail2014} and then in 2015 \cite{ctaRail2015} available online. The video comprises of scenes from train stations platforms, subway station platforms, subway tunnels, railroad tracks within highways and urban areas. The entire video sequence captured at a high frame-rate is used for current experiments processing every 200th frame. The resultant reference and query databases have 656 and 738 image frames respectively.

\begin{figure}
 \includegraphics[scale=0.25]{cta-datasetTrajSampleImages}
 \caption{CTA Dataset Trajectory Aerial View with sample images. Marked Trajectory Source - \cite{ctaTrajGMap}}
 \label{fig:ctaTraj}
\end{figure}


\subsubsection{Campus Indoor Outdoor}
The Campus Indoor Outdoor dataset comprises of two videos with repeated traversal of campus from outside lawn to inside corridor \cite{indoorOutdoor1,indoorOutdoor2}. The videos are recorded using a hand-held device and has jerky motion with huge motion blur. The raw videos are cropped to remove the comments at the bottom and an overlaid navigation display on the right side. The videos are also snipped from beginning so that the starting point is aligned in both the sequences. The dataset therefore comprises of scenes from outside the campus with trees, grass and field road, and from inside the campus traversing through entrance hall, staircase, lobby and corridor. The reference and query database is processed by using every 10th image and therefore uses 355 and 300 frames respectively.

\subsubsection{Ground Truth}
The place recognition ground truth for both the datasets is generated manually for intermittent frames and then interpolated for rest of the image sequence. A query image is considered to be a true positive match for the reference image if its index lies within a range of 5 image frames from the ground truth index.

\subsubsection{SeqSLAM parameters}
The parameters for SeqSLAM used for all the experiments are shown in Table \ref{table:seqSLAMParams}.

\begin{table}[!htbp]
\caption{SeqSLAM parameters.}
 \begin{tabular}{|c|p{4cm}|p{2.5cm}|}
 \hline
  $S$ & Image Down-sampling Size & 32x32 \\
  \hline
  $P$ & Patch Normalization Window Size & {2,4,8,16} \\
  \hline
  $O$ & Image Matching Offset Range & $\pm10$ \\
  \hline
  $D_s$ & Sequence Length & 10 \\
  \hline
  $R$ & Contrast Enhancement Window Size & {10,20,40,80,160} \\
  \hline
  $V$ & Sequence Search Velocity Range & $1\pm0.4$ \\
  \hline
  $\mu$ & Trajectory Uniqueness Threshold & Varied from 0 to 255 \\
 \hline
 \end{tabular}
\label{table:seqSLAMParams}
\end{table}

\section{Results}
The place recognition performance is measured using maximum F1 Score by varying the trajectory uniqueness parameter (described in \cite{Milford2012}), that is, the threshold for deciding a correctly matched place. We also varied two of the parameters of SeqSLAM method that are known to affect the performance, in order to understand the performance changes by using the proposed approach. The performance improvement is as shown in Figure \ref{fig:performanceChart} and the effect of parameters is discussed in subsequent section. 

\begin{figure*}[t]
\centering
\begin{tabular}[t]{c}
\includegraphics[scale=0.5]{cta-bar-graph}\\
\includegraphics[scale=0.5]{campus-io-bar-graph}
\end{tabular}
 \caption{Performance chart showing maximum F1 Score. The first row corresponds to the CTA-Rail dataset and second row to the Campus Indoor-Outdoor dataset. The performance improves with increasing the parameter value R, where vanilla SeqSLAM performs equally good as the proposed approach. The patch normlization Size (P) parameter with value 4 tends to give maximum score as compared to others.}
 \label{fig:performanceChart}
\end{figure*}

Figure \ref{fig:sadMat} shows the ground truth and the place recognition matches (without thresholding) corresponding to different parameter settings for both vanilla SeqSLAM and proposed method. The results in first row correspond to Campus Indoor-Outdoor dataset and second row to CTA Rail dataset. The performance improvement is large for both the datasets for smaller values of $R$ (contrast enhancement window size). The large $R$ values help the vanilla method to attain performance equivalent to the proposed approach as shown in Figure \ref{fig:sadMat}. The effect of dataset segmentation can be easily seen and understood in the result images in form of rectangular dark and light patches in the SAD matrix. 

\newcommand{\imgH}{3cm}
\newcommand{\imgW}{4cm}
\begin{figure*}[!h]
 \begin{tabular*}{\textwidth}[t]{cccc}
  \includegraphics[width=\imgW,height=\imgH]{campus-io-without-bad-101} &
  \includegraphics[width=\imgW,height=\imgH]{campus-io-with-bad-71} &
  \includegraphics[width=\imgW,height=\imgH]{campus-io-without-good-105} &
  \includegraphics[width=\imgW,height=\imgH]{campus-io-with-good-75} \\
  (a) F Score = 0.46 & (b) F Score = \textbf{0.74} & (c) F Score = 0.72 & (d) F Score = \textbf{0.75} \\
  SeqSLAM & Proposed Approach & SeqSLAM & Proposed Approach \\
  \multicolumn{2}{c}{\textbf{R = 10}, P = 8} & \multicolumn{2}{c}{\textbf{R = 160}, P = 8} \\
  \multicolumn{4}{c}{\emph{Campus Indoor-Outdoor Dataset}} \\
  \\
  \includegraphics[width=\imgW,height=\imgH]{cta-rail-without-bad-106} &
  \includegraphics[width=\imgW,height=\imgH]{cta-rail-with-bad-306} &
  \includegraphics[width=\imgW,height=\imgH]{cta-rail-without-good-110} &
  \includegraphics[width=\imgW,height=\imgH]{cta-rail-with-good-310} \\
  (e) F Score = 0.61 & (f) F Score = \textbf{0.82} & (g) F Score = 0.80 & (h) F Score = \textbf{0.82} \\
  SeqSLAM & Proposed Approach & SeqSLAM & Proposed Approach \\
  \multicolumn{2}{c}{\textbf{R = 10}, P = 4} & \multicolumn{2}{c}{\textbf{R = 160}, P = 4} \\
  \multicolumn{4}{c}{\emph{CTA Rail Dataset}} \\
 \end{tabular*}
 \caption{The SAD (Sum of absolute difference) matrix with reference database as rows and query database as columns. The ground truth is marked in blue, loop closures in red and true positives in yellow. The first and second row corresponds to Campus Indoor-Outdoor and CTA-Rail dataset respectively. Results in (a)-(b) and (e)-(f) correspond to smaller normalization window for vanilla SeqSLAM and proposed approach respectively while (c)-(d) and (g)-(h) correspond to larger normalization window. The dataset segmentation can be seen as rectangular dark and light patches. The images here show that performance improvement is large for smaller R values and with larger R values, performance of vanilla SeqSLAM method approaches to that of proposed method.}
 \label{fig:sadMat}

\end{figure*}


\section{Discussion}
\subsection{Effect of SeqSLAM parameters}
\subsubsection{Sequence Normalization Zone Width ($R$)}
This parameter is used to set the window size for locally enhancing the contrast of the match scores, that is, normalizing the score values in a local window. As shown in Figure \ref{fig:performanceChart}, for vanilla SeqSLAM method, the performance improves with increasing the value of this parameter. This is also expected because normalizing over a larger image sequence balances the overall variation in scores, but it leads to suppressing of place recognition corresponding to images which have low matching scores. On the other hand, using segmented regions to set the window size, effectively enhances the contrast of matching scores in appropriate regions and yields correct matching pairs. The performance is, therefore, most of the times better than the best achieved using vanilla approach. Moreover, setting the window size large is not appropriate for large datasets and long time navigation. Fig. \ref{fig:RPerformance} shows a performance comparison for both the datasets with respect to the parameter $R$.

\begin{figure}
 \includegraphics[scale=0.4]{RPerformance}
 \caption{Performance comparison of proposed method and vanilla SeqSLAM with respect to parameter $R$ for CTA and Campus datasets.}
 \label{fig:RPerformance}
\end{figure}


\subsubsection{Patch Normalization Window Size ($P$)}
The images used for finding SAD score are preprocessed by down-sampling them to the size of $32\mathbf{x}32$ and patch normalizing them in order to counter the change in appearance of their matching counterparts. Depending on the type of environment and corresponding imagery, the patch normalization window size can give different performance, but a higher value is usually recommended. In the experiments conducted here, we found that patch normalization window size of 4 and 8 for the given down-sampling image size gives a better performance.

\section{Conclusion}

\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

\section*{ACKNOWLEDGMENT}

The preferred spelling of the word ÒacknowledgmentÓ in America is without an ÒeÓ after the ÒgÓ. Avoid the stilted expression, ÒOne of us (R. B. G.) thanks . . .Ó  Instead, try ÒR. B. G. thanksÓ. Put sponsor acknowledgments in the unnumbered footnote on the first page.

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,ral-icra-2017}

\end{document}
